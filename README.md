# Flood Detection Using Deep Learning and Satellite Imagery

This project presents a binary semantic segmentation model based on U-Net to detect flood-affected regions in satellite images. It aims to provide an automated, efficient, and scalable flood detection solution to improve early warning systems and aid in disaster response.

---

## Overview

Natural disaster management is often challenged by high operational costs, time delays, and manual analysis. This project addresses those issues by using deep learning for automatic flood detection from aerial imagery.

Key features:
- U-Net-based segmentation model implemented using TensorFlow/Keras.
- Binary segmentation to classify pixels as flood or non-flood.
- Visualization of model predictions after each epoch for qualitative analysis.
- Multiple model versions to evaluate and improve segmentation performance.

---

## Folder Structure

```
flood-detection/
│
├── trained_weights/                  # Saved trained model weights
├── flood-segmentation-model-v1.ipynb # Initial U-Net segmentation model
├── flood-segmentation-model-v2.ipynb # Improved model version with Dice loss and higher resolution
├── Model-Load-make-prediction.ipynb  # Script to load model and make predictions
├── requirements.txt                 # Python package dependencies
├── README.md                        # Project documentation
```

---

## Dataset

The dataset used in this project is **FloodNet-Supervised_v1.0**, a public dataset consisting of annotated flood scenes captured by UAVs and satellites.

- Total images: 2343 (Train: 1445, Validation: 450, Test: 448)
- Image resolution: Varies; resized to 256x256 in v1, and to 512x512 in v2.
- Each image has a corresponding semantic mask with 10 classes:
  - `0`: Background
  - `1`: Building-flooded
  - `2`: Building-non-flooded
  - `3`: Road-flooded
  - `4`: Road-non-flooded
  - `5`: Water
  - `6`: Tree
  - `7`: Vehicle
  - `8`: Pool
  - `9`: Grass

For binary flood segmentation, the following class IDs are considered as *flood*:  
`[1, 3, 5]` → Building-flooded, Road-flooded, and Water.

**Dataset Repository:**  
[https://github.com/BinaLab/FloodNet-Supervised_v1.0](https://github.com/BinaLab/FloodNet-Supervised_v1.0)

**Direct Download (Dropbox):**  
[https://www.dropbox.com/scl/fo/k33qdif15ns2qv2jdxvhx](https://www.dropbox.com/scl/fo/k33qdif15ns2qv2jdxvhx)

---

## Project Structure Summary

- **v1**: Basic implementation of U-Net with binary cross-entropy loss.
- **v2**: Enhanced model with:
  - Combined **Dice coefficient** and **accuracy** as training metrics.
  - **Loss function** = Binary Cross Entropy + Dice Loss.
  - **Input resolution** increased to **512x512** in both preprocessing and model input.
  - Added **epoch-wise predictions** and image visualizations.
  - Increased **training epochs** to 100 for deeper convergence.
  - Decreased **learning rate** to 5e-5 for finer gradient updates.
  - Implemented robust **callback functions** including `ModelCheckpoint` and `PlotLearning`.

---

## Requirements

All dependencies required to run the project are listed in `requirements.txt`.

To install:
```bash
pip install -r requirements.txt
```

---

## Training the Model

Both model versions are implemented in Jupyter Notebooks:

### Version 1
```bash
flood-segmentation-model-v1.ipynb
```

- U-Net architecture
- 256x256 image resizing
- Binary cross-entropy loss
- Fewer training epochs

### Version 2
```bash
flood-segmentation-model-v2.ipynb
```

- Enhanced segmentation with BCE + Dice loss
- 512x512 resolution
- 100 training epochs
- Image prediction shown per epoch

Binary masks are generated by mapping multi-class labels `[1, 3, 5]` to class `1` (flood), and others to `0`.

---

## Output

- **Binary Segmentation Mask**: Flooded vs. Non-flooded areas.
- **Epoch-wise Visual Output**: Concatenated display of:
  - Original image
  - Predicted mask
  - Overlay of mask on original

![image](https://github.com/user-attachments/assets/d2906b9a-6213-41b2-b171-7e8acc81ff08)
![image](https://github.com/user-attachments/assets/d102e9ce-ae1f-43b2-8112-5c22f38eb36e)
![image](https://github.com/user-attachments/assets/64589190-6e01-47aa-9eef-75b781dd2b35)
![image](https://github.com/user-attachments/assets/9128128d-4ae5-4aec-a9c2-c5df832d882a)


---

## Pretrained Model and Inference

Trained model weights are saved in the `trained_weights/` folder.

To load and make predictions:
```bash
Model-Load-make-prediction.ipynb
```

This notebook loads the trained model and performs inference on new images using the same preprocessing pipeline.

---

## Notes

- `ModelCheckpoint` saves the best model during training.
- Custom callback `PlotLearning` visualizes predictions during training.
- Ensure dataset is pre-downloaded into the working directory before running notebooks.

---

## License

This project is for academic and research purposes. Dataset usage is governed by the terms and conditions of the original FloodNet dataset authors.
